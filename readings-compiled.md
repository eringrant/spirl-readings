---
bibliography: 'all.bib'
csl: 'chicago-syllabus.csl'
---

Reinforcement Learning
======================

-   Peter Dayan and Geoffrey E. Hinton, “Feudal Reinforcement Learning,”
    in *NeurIPS*, 1992,
    <http://papers.nips.cc/paper/714-feudal-reinforcement-learning>.
-   Satinder P. Singh, “Transfer of Learning by Composing Solutions of
    Elemental Sequential Tasks” 8 (1992): 323–339,
    <https://doi.org/10.1007/BF00992700>.
-   Peter Dayan and Geoffrey E Hinton, “Feudal Reinforcement Learning,”
    in *Advances in Neural Information Processing Systems*, 1993,
    271–278.
-   Sebastian Thrun and Anton Schwartz, “Finding Structure in
    Reinforcement Learning,” in *Advances in Neural Information
    Processing Systems*, 1995, 385–392.
-   Ronald Parr and Stuart J Russell, “Reinforcement Learning with
    Hierarchies of Machines,” in *NeurIPS*, 1998, 1043–1049.
-   Richard S Sutton, Doina Precup, and Satinder Singh, “Between MDPs
    and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement
    Learning” 112, nos. 1-2 (1999): 181–211.
-   Thomas G Dietterich, “Hierarchical Reinforcement Learning with the
    MAXQ Value Function Decomposition” 13 (2000): 227–303.
-   Michael L. Littman, Richard S. Sutton, and Satinder P. Singh,
    “Predictive Representations of State,” in *NeurIPS*, 2001.
-   Kfir Y Levy and Nahum Shimkin, “Unified Inter and Intra Options
    Learning Using Policy Gradient Methods,” in *European Workshop on
    Reinforcement Learning* (Springer, 2011), 153–164.
-   Carlos Diuk et al., “Divide and Conquer: Hierarchical Reinforcement
    Learning and Task Decomposition in Humans,” in *Computational and
    Robotic Models of the Hierarchical Organization of Behavior*
    (Springer, 2013), 271–291.

Cognitive Science
=================

-   Rachit Dubey et al., “Investigating Human Priors for Playing Video
    Games,” in *ICML*, 2018.
