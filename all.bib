@inproceedings{dayan1992feudal,
  title = {Feudal Reinforcement Learning},
  author = {Dayan, Peter and Hinton, Geoffrey E.},
  booktitle = {NeurIPS},
  year = {1992},
  url = {http://papers.nips.cc/paper/714-feudal-reinforcement-learning},
}

@article{singh1992transfer,
  title = {Transfer of Learning by Composing Solutions of Elemental Sequential Tasks},
  author = {Singh, Satinder P.},
  volume = {8},
  pages = {323--339},
  year = {1992},
  journal={Machine Learning},
  url = {https://link.springer.com/article/10.1007/BF00992700},
}

@inproceedings{dayan1993feudal,
  title = {Feudal reinforcement learning},
  author = {Dayan, Peter and Hinton, Geoffrey E},
  booktitle = {NeurIPS},
  pages = {271--278},
  year = {1993},
}

@inproceedings{thrun1995finding,
  title = {Finding structure in reinforcement learning},
  author = {Thrun, Sebastian and Schwartz, Anton},
  booktitle = {NeurIPS},
  pages = {385--392},
  year = {1995},
}

@inproceedings{parr1998reinforcement,
  title = {Reinforcement learning with hierarchies of machines},
  author = {Parr, Ronald and Russell, Stuart J},
  booktitle = {NeurIPS},
  pages = {1043--1049},
  year = {1998},
}

@article{sutton1999between,
  title = {Between {MDPs} and semi-{MDPs}: A framework for temporal abstraction in reinforcement learning},
  author = {Sutton, Richard S and Precup, Doina and Singh, Satinder},
  volume = {112},
  number = {1-2},
  pages = {181--211},
  publisher = {Elsevier},
  year = {1999},
}

@article{dietterich2000hierarchical,
  title = {Hierarchical reinforcement learning with the {MAXQ} value function decomposition},
  author = {Dietterich, Thomas G},
  volume = {13},
  pages = {227--303},
  year = {2000},
  url={https://www.jair.org/index.php/jair/article/view/10266}
}

@inproceedings{littman2001predictive,
  title = {Predictive Representations of State},
  author = {Littman, Michael L. and Sutton, Richard S. and Singh, Satinder P.},
  booktitle = {NeurIPS},
  year = {2001},
}

@inproceedings{levy2011unified,
  title = {Unified inter and intra options learning using policy gradient methods},
  author = {Levy, Kfir Y and Shimkin, Nahum},
  booktitle = {European Workshop on Reinforcement Learning},
  pages = {153--164},
  organization = {Springer},
  year = {2011},
}

@incollection{diuk2013divide,
  title = {Divide and conquer: hierarchical reinforcement learning and task decomposition in humans},
  author = {Diuk, Carlos and Schapiro, Anna and C{ó}rdova, Natalia and Ribas-Fernandes, Jos{é} and Niv, Yael and Botvinick, Matthew},
  booktitle = {Computational and robotic models of the hierarchical organization of behavior},
  pages = {271--291},
  publisher = {Springer},
  year = {2013},
}

@article{gershman2015novelty,
  title = {Novelty and Inductive Generalization in Human Reinforcement Learning},
  author = {Gershman, Samuel J. and Niv, Yael},
  volume = {7},
  number = {3},
  pages = {391--415},
  year = {2015},
  url = {https://doi.org/10.1111/tops.12138},
}

@article{ghavamzadeh2015bayesian,
  title = {Bayesian reinforcement learning: A survey},
  author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv and others},
  volume = {8},
  number = {5-6},
  pages = {359--483},
  publisher = {Now Publishers, Inc.},
  year = {2015},
  url={https://arxiv.org/abs/1609.04436}
}

@inproceedings{andreas2016neural,
  title = {Neural module networks},
  author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  booktitle = {CVPR},
  pages = {39--48},
  year = {2016},
  url={https://arxiv.org/abs/1511.02799}
}

@article{optioncritic,
  title = {The Option-Critic Architecture},
  author = {Bacon, Pierre{-}Luc and Harb, Jean and Precup, Doina},
  volume = {abs/1609.05140},
  year = {2016},
  url = {http://arxiv.org/abs/1609.05140},
}

@article{duan2016rl,
  author    = {Yan Duan and
               John Schulman and
               Xi Chen and
               Peter L. Bartlett and
               Ilya Sutskever and
               Pieter Abbeel},
  title     = {RL{\textdollar}{\^{}}2{\textdollar}: Fast Reinforcement Learning via
               Slow Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.02779},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.02779},
  archivePrefix = {arXiv},
  eprint    = {1611.02779},
  timestamp = {Mon, 03 Sep 2018 12:15:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/DuanSCBSA16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
}

@article{silver2016mastering,
  title = {Mastering the game of {Go} with deep neural networks and tree search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  volume = {529},
  number = {7587},
  pages = {484},
  publisher = {Nature Publishing Group},
  year = {2016},
}

@article{wang2016learning,
  author    = {Jane X. Wang and
               Zeb Kurth{-}Nelson and
               Dhruva Tirumala and
               Hubert Soyer and
               Joel Z. Leibo and
               R{\'{e}}mi Munos and
               Charles Blundell and
               Dharshan Kumaran and
               Matthew Botvinick},
  title     = {Learning to reinforcement learn},
  journal   = {CoRR},
  volume    = {abs/1611.05763},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.05763},
  archivePrefix = {arXiv},
  eprint    = {1611.05763},
  timestamp = {Mon, 13 Aug 2018 16:47:12 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/WangKTSLMBKB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{andreas2017modular,
  title = {Modular multitask reinforcement learning with policy sketches},
  author = {Andreas, Jacob and Klein, Dan and Levine, Sergey},
  booktitle = {ICML},
  year = {2017},
  url={https://arxiv.org/abs/1611.01796}
}

@phdthesis{duan2017meta,
  title = {Meta-learning for control},
  author = {Duan, Rocky},
  year = {2017},
}

@inproceedings{finn2017model,
  title = {Model-agnostic meta-learning for fast adaptation of deep networks},
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle = {ICML},
  year = {2017},
  url = {https://arxiv.org/abs/1703.03400},
}

@article{silver2017mastering,
  title = {Mastering the game of {Go} without human knowledge},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  volume = {550},
  number = {7676},
  pages = {354},
  publisher = {Nature Publishing Group},
  year = {2017},
}

@inproceedings{vezhnevets2017feudal,
  title = {FeUdal networks for hierarchical reinforcement learning},
  author = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle = {ICML},
  pages = {3540--3549},
  year = {2017},
  url={https://arxiv.org/abs/1703.01161}
}

@inproceedings{abel2018policy,
  title = {Policy and Value Transfer in Lifelong Reinforcement Learning},
  author = {Abel, David and Jinnai, Yuu and Guo, Sophie Yue and Konidaris, George and Littman, Michael L.},
  booktitle = {ICML},
  year = {2018},
  url = {http://proceedings.mlr.press/v80/abel18b.html},
}

@inproceedings{chang2018automatically,
  title = {Automatically Composing Representation Transformations as a Means for Generalization},
  author = {Chang, Michael B. and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L.},
  booktitle = {Neural Abstract Machines and Program Induction Workshop, ICML},
  year = {2018},
}

@inproceedings{dubey2018investigating,
  title = {Investigating Human Priors for Playing Video Games},
  author = {Dubey, Rachit and Agrawal, Pulkit and Pathak, Deepak and Griffiths, Thomas L and Efros, Alexei A},
  booktitle = {ICML},
  year = {2018},
  url={https://arxiv.org/abs/1802.10217}
}

@inproceedings{frans2018meta,
  title = {Meta-learning shared hierarchies},
  author = {Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
  booktitle = {ICLR},
  year = {2018},
  url = {https://arxiv.org/abs/1710.09767},
}

@article{botvinick2009hierarchically,
  title={Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective},
  author={Botvinick, Matthew M and Niv, Yael and Barto, Andrew C},
  journal={Cognition},
  volume={113},
  number={3},
  pages={262--280},
  year={2009},
  publisher={Elsevier},
  url={https://www.ncbi.nlm.nih.gov/pubmed/18926527}
}

@inproceedings{ok2018exploration,
  title={Exploration in Structured Reinforcement Learning},
  author={Ok, Jungseul and Proutiere, Alexandre and Tranos, Damianos},
  booktitle = {NeurIPS},
  year={2018},
  url={https://arxiv.org/abs/1806.00775}
}

@incollection{diuk2013divide,
  title={Divide and conquer: hierarchical reinforcement learning and task decomposition in humans},
  author={Diuk, Carlos and Schapiro, Anna and C{\'o}rdova, Natalia and Ribas-Fernandes, Jos{\'e} and Niv, Yael and Botvinick, Matthew},
  booktitle={Computational and robotic models of the hierarchical organization of behavior},
  pages={271--291},
  year={2013},
  publisher={Springer},
  url={https://link.springer.com/chapter/10.1007/978-3-642-39875-9_12}
}

@article{boureau2015deciding,
  title={Deciding how to decide: Self-control and meta-decision making},
  author={Boureau, Y-Lan and Sokol-Hessner, Peter and Daw, Nathaniel D},
  journal={Trends in cognitive sciences},
  volume={19},
  number={11},
  pages={700--710},
  year={2015},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/pii/S1364661315002041}
}

@inproceedings{ponsen2009abstraction,
  title={Abstraction and generalization in reinforcement learning: A summary and framework},
  author={Ponsen, Marc and Taylor, Matthew E and Tuyls, Karl},
  booktitle={International Workshop on Adaptive and Learning Agents},
  pages={1--32},
  year={2009},
  organization={Springer},
  url={https://link.springer.com/chapter/10.1007/978-3-642-11814-2_1}
}

@article{taylor2009transfer,
  title={Transfer learning for reinforcement learning domains: A survey},
  author={Taylor, Matthew E and Stone, Peter},
  journal={JMLR},
  volume={10},
  number={Jul},
  pages={1633--1685},
  year={2009},
  url={http://www.jmlr.org/papers/v10/taylor09a.html}
}

@article{trommershauser2008decision,
  title={Decision making, movement planning and statistical decision theory},
  author={Trommersh{\"a}user, Julia and Maloney, Laurence T and Landy, Michael S},
  journal={Trends in cognitive sciences},
  volume={12},
  number={8},
  pages={291--297},
  year={2008},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/pii/S1364661308001538}
}

@inproceedings{tamar2016value,
  title={Value iteration networks},
  author={Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
  booktitle={NeurIPS},
  pages={2154--2162},
  year={2016},
  url={https://arxiv.org/abs/1602.02867}
}

@inproceedings{silver2017predictron,
  title={The predictron: End-to-end learning and planning},
  author={David Silver and
               Hado van Hasselt and
               Matteo Hessel and
               Tom Schaul and
               Arthur Guez and
               Tim Harley and
               Gabriel Dulac{-}Arnold and
               David P. Reichert and
               Neil C. Rabinowitz and
               Andr{\'{e}} Barreto and
               Thomas Degris},
  booktitle={ICML},
  pages={3191--3199},
  year={2017},
  url={https://arxiv.org/abs/1612.08810}
}

@incollection{sutton1995td,
  title={TD models: Modeling the world at a mixture of time scales},
  author={Sutton, Richard S},
  booktitle={Machine Learning Proceedings 1995},
  pages={531--539},
  year={1995},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/pii/B9781558603776500724}
}

@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={AAMAS},
  pages={761--768},
  year={2011},
  url={http://www.ifaamas.org/Proceedings/aamas2011/papers/A6_R70.pdf}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={ICML},
  pages={1312--1320},
  year={2015},
  url={http://proceedings.mlr.press/v37/schaul15.html}
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={NeurIPS},
  pages={5048--5058},
  year={2017},
  url={https://arxiv.org/abs/1707.01495}
}

@article{sanchez2018graph,
  title={Graph networks as learnable physics engines for inference and control},
  author={Sanchez-Gonzalez, Alvaro and Heess, Nicolas and Springenberg, Jost Tobias and Merel, Josh and Riedmiller, Martin and Hadsell, Raia and Battaglia, Peter},
  booktitle={ICML},
  year={2018},
  url={https://arxiv.org/abs/1806.01242}
}

@inproceedings{hausman2018learning,
  title={Learning an embedding space for transferable robot skills},
  author={Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  booktitle = {ICLR},
  year={2018},
  url={https://openreview.net/forum?id=rk07ZXZRb}
}

@article{gupta2018meta,
  title={Meta-Reinforcement Learning of Structured Exploration Strategies},
  author={Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  booktitle={NeurIPS},
  year={2018},
  url={https://arxiv.org/abs/1802.07245}
}

@inproceedings{saemundsson2018meta,
  title={Meta Reinforcement Learning with Latent Variable Gaussian Processes},
  author={S{\ae}mundsson, Steind{\'o}r and Hofmann, Katja and Deisenroth, Marc Peter},
  booktitle={UAI},
  year={2018},
  url={https://arxiv.org/abs/1803.07551}
}

@inproceedings{devin2017learning,
  title={Learning modular neural network policies for multi-task and multi-robot transfer},
  author={Devin, Coline and Gupta, Abhishek and Darrell, Trevor and Abbeel, Pieter and Levine, Sergey},
  booktitle={ICRA},
  pages={2169--2176},
  year={2017},
  url={https://arxiv.org/abs/1609.07088}
}

@inproceedings{hausman2017multi,
  title={Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets},
  author={Hausman, Karol and Chebotar, Yevgen and Schaal, Stefan and Sukhatme, Gaurav and Lim, Joseph J},
  booktitle={NeurIPS},
  pages={1235--1245},
  year={2017},
  url={https://arxiv.org/abs/1705.10479}
}

@inproceedings{wingate2011bayesian,
  title={Bayesian policy search with policy priors},
  author={Wingate, David and Goodman, Noah D and Roy, Daniel M and Kaelbling, Leslie P and Tenenbaum, Joshua B}
  booktitle={IJCAI},
  year={2011},
  url={http://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/download/3306/3478}
}

@article{heess2016learning,
  title={Learning and transfer of modulated locomotor controllers},
  author={Heess, Nicolas and Wayne, Greg and Tassa, Yuval and Lillicrap, Timothy and Riedmiller, Martin and Silver, David},
  journal={arXiv preprint arXiv:1610.05182},
  year={2016}
  url={https://arxiv.org/abs/1610.05182}
}

@inproceedings{osband2018randomized,
  title={Randomized Prior Functions for Deep Reinforcement Learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={NeurIPS},
  year={2018},
  url={https://arxiv.org/abs/1806.03335}
}

@article{johannink2018residual,
  title={Residual reinforcement learning for robot control},
  author={Johannink, Tobias and Bahl, Shikhar and Nair, Ashvin and Luo, Jianlan and Kumar, Avinash and Loskyll, Matthias and Ojea, Juan Aparicio and Solowjow, Eugen and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.03201},
  year={2018},
  url={https://arxiv.org/abs/1812.03201}
}

@inproceedings{lowrey2018plan,
  title={Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control},
  author={Lowrey, Kendall and Rajeswaran, Aravind and Kakade, Sham and Todorov, Emanuel and Mordatch, Igor},
  booktitle = {ICLR},
  year={2018},
  url={https://arxiv.org/abs/1811.01848}
}

@inproceedings{ghosh2018divide,
  title={Divide-and-conquer reinforcement learning},
  author={Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
  booktitle = {ICLR},
  year={2017},
  url={https://arxiv.org/abs/1711.09874}
}
