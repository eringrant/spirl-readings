@inproceedings{dayan1992feudal,
  title = {Feudal Reinforcement Learning},
  author = {Dayan, Peter and Hinton, Geoffrey E.},
  booktitle = {NeurIPS},
  year = {1992},
  url = {http://papers.nips.cc/paper/714-feudal-reinforcement-learning},
}

@article{singh1992transfer,
  title = {Transfer of Learning by Composing Solutions of Elemental Sequential Tasks},
  author = {Singh, Satinder P.},
  volume = {8},
  pages = {323--339},
  journaltitle = {Machine Learning},
  year = {1992},
  url = {https://link.springer.com/article/10.1007/BF00992700},
}

@inproceedings{thrun1994finding,
  title = {Finding structure in reinforcement learning},
  author = {Thrun, Sebastian and Schwartz, Anton},
  booktitle = {NeurIPS},
  year = {1994},
  url = {https://papers.nips.cc/paper/887-finding-structure-in-reinforcement-learning},
}

@inproceedings{sutton1995td,
  title = {TD models: Modeling the world at a mixture of time scales},
  author = {Sutton, Richard S},
  booktitle = {ICML},
  year = {1995},
  url = {https://www.sciencedirect.com/science/article/pii/B9781558603776500724},
}

@inproceedings{parr1997reinforcement,
  title = {Reinforcement learning with hierarchies of machines},
  author = {Parr, Ronald and Russell, Stuart J},
  booktitle = {NeurIPS},
  year = {1997},
  url = {https://papers.nips.cc/paper/1384-reinforcement-learning-with-hierarchies-of-machines},
}

@article{sutton1999between,
  title = {Between {MDPs} and semi-{MDPs}: A framework for temporal abstraction in reinforcement learning},
  author = {Sutton, Richard S and Precup, Doina and Singh, Satinder},
  volume = {112},
  number = {1-2},
  pages = {181--211},
  journaltitle = {Artificial Intelligence},
  publisher = {Elsevier},
  year = {1999},
  url = {https://www.sciencedirect.com/science/article/pii/S0004370299000521},
}

@article{dietterich2000hierarchical,
  title = {Hierarchical reinforcement learning with the {MAXQ} value function decomposition},
  author = {Dietterich, Thomas G},
  volume = {13},
  pages = {227--303},
  journaltitle = {Journal of Artificial Intelligence Research},
  year = {2000},
  url = {https://arxiv.org/abs/cs/9905014},
}

@inproceedings{littman2001predictive,
  title = {Predictive Representations of State},
  author = {Littman, Michael L. and Sutton, Richard S. and Singh, Satinder P.},
  booktitle = {NeurIPS},
  year = {2001},
  url = {https://papers.nips.cc/paper/1983-predictive-representations-of-state},
}

@article{trommershauser2008decision,
  title = {Decision making, movement planning and statistical decision theory},
  author = {Trommershäuser, Julia and Maloney, Laurence T and Landy, Michael S},
  volume = {12},
  number = {8},
  pages = {291--297},
  journaltitle = {Trends in cognitive sciences},
  publisher = {Elsevier},
  year = {2008},
  url = {https://www.sciencedirect.com/science/article/pii/S1364661308001538},
}

@article{botvinick2009hierarchically,
  title = {Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective},
  author = {Botvinick, Matthew M and Niv, Yael and Barto, Andrew C},
  volume = {113},
  number = {3},
  pages = {262--280},
  journaltitle = {Cognition},
  publisher = {Elsevier},
  year = {2009},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/18926527},
}

@inproceedings{ponsen2009abstraction,
  title = {Abstraction and generalization in reinforcement learning: A summary and framework},
  author = {Ponsen, Marc and Taylor, Matthew E and Tuyls, Karl},
  booktitle = {International Workshop on Adaptive and Learning Agents},
  pages = {1--32},
  organization = {Springer},
  year = {2009},
  url = {https://link.springer.com/chapter/10.1007/978-3-642-11814-2_1},
}

@article{taylor2009transfer,
  title = {Transfer learning for reinforcement learning domains: A survey},
  author = {Taylor, Matthew E and Stone, Peter},
  volume = {10},
  number = {Jul},
  pages = {1633--1685},
  journaltitle = {JMLR},
  year = {2009},
  url = {http://www.jmlr.org/papers/v10/taylor09a.html},
}

@inproceedings{levy2011unified,
  title = {Unified inter and intra options learning using policy gradient methods},
  author = {Levy, Kfir Y and Shimkin, Nahum},
  booktitle = {European Workshop on Reinforcement Learning},
  organization = {Springer},
  year = {2011},
  url = {https://ewrl.files.wordpress.com/2011/08/ewrl2011_submission_21.pdf},
}

@inproceedings{sutton2011horde,
  title = {Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author = {Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle = {AAMAS},
  year = {2011},
  url = {http://www.ifaamas.org/Proceedings/aamas2011/papers/A6_R70.pdf},
}

@inproceedings{wingate2011bayesian,
  title = {Bayesian policy search with policy priors},
  author = {Wingate, David and Goodman, Noah D and Roy, Daniel M and Kaelbling, Leslie P and Tenenbaum, Joshua B},
  booktitle = {IJCAI},
  year = {2011},
  url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/download/3306/3478},
}

@incollection{diuk2013divide,
  title = {Divide and conquer: hierarchical reinforcement learning and task decomposition in humans},
  author = {Diuk, Carlos and Schapiro, Anna and Córdova, Natalia and Ribas-Fernandes, José and Niv, Yael and Botvinick, Matthew},
  booktitle = {Computational and robotic models of the hierarchical organization of behavior},
  pages = {271--291},
  publisher = {Springer},
  year = {2013},
  url = {https://link.springer.com/chapter/10.1007%2F978-3-642-39875-9_12},
}

@article{boureau2015deciding,
  title = {Deciding how to decide: Self-control and meta-decision making},
  author = {Boureau, Y-Lan and Sokol-Hessner, Peter and Daw, Nathaniel D},
  volume = {19},
  number = {11},
  pages = {700--710},
  journaltitle = {Trends in cognitive sciences},
  publisher = {Elsevier},
  year = {2015},
  url = {https://www.sciencedirect.com/science/article/pii/S1364661315002041},
}

@article{gershman2015novelty,
  title = {Novelty and Inductive Generalization in Human Reinforcement Learning},
  author = {Gershman, Samuel J. and Niv, Yael},
  volume = {7},
  number = {3},
  pages = {391--415},
  journaltitle = {Topics in cognitive science},
  year = {2015},
  url = {https://onlinelibrary.wiley.com/doi/full/10.1111/tops.12138},
}

@article{ghavamzadeh2015bayesian,
  title = {Bayesian reinforcement learning: A survey},
  author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv and others},
  volume = {8},
  number = {5-6},
  pages = {359--483},
  journaltitle = {Foundations and Trends in Machine Learning},
  publisher = {Now Publishers, Inc.},
  year = {2015},
  url = {https://arxiv.org/abs/1609.04436},
}

@inproceedings{schaul2015universal,
  title = {Universal value function approximators},
  author = {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle = {ICML},
  year = {2015},
  url = {http://proceedings.mlr.press/v37/schaul15.html},
}

@article{duan2016rl,
  title = {RL2: Fast Reinforcement Learning via Slow Reinforcement Learning},
  author = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L. and Sutskever, Ilya and Abbeel, Pieter},
  journaltitle = {arXiv preprint arXiv:1611.02779},
  year = {2016},
  url = {http://arxiv.org/abs/1611.02779},
}

@article{heess2016learning,
  title = {Learning and transfer of modulated locomotor controllers},
  author = {Heess, Nicolas and Wayne, Greg and Tassa, Yuval and Lillicrap, Timothy and Riedmiller, Martin and Silver, David},
  journaltitle = {arXiv preprint arXiv:1610.05182},
  year = {2016},
  url = {https://arxiv.org/abs/1610.05182},
}

@inproceedings{tamar2016value,
  title = {Value iteration networks},
  author = {Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
  booktitle = {NeurIPS},
  year = {2016},
  url = {https://arxiv.org/abs/1602.02867},
}

@article{wang2016learning,
  title = {Learning to reinforcement learn},
  author = {Wang, Jane X. and Kurth{-}Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Munos, Rémi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matthew},
  volume = {abs/1611.05763},
  journaltitle = {CoRR},
  year = {2016},
  url = {http://arxiv.org/abs/1611.05763},
  eprint = {1611.05763},
}

@inproceedings{andreas2017modular,
  title = {Modular multitask reinforcement learning with policy sketches},
  author = {Andreas, Jacob and Klein, Dan and Levine, Sergey},
  booktitle = {ICML},
  year = {2017},
  url = {https://arxiv.org/abs/1611.01796},
}

@inproceedings{bacon2017option,
  title = {The Option-Critic Architecture},
  author = {Bacon, Pierre{-}Luc and Harb, Jean and Precup, Doina},
  booktitle = {AAAI},
  year = {2017},
  url = {http://arxiv.org/abs/1609.05140},
}

@inproceedings{devin2017learning,
  title = {Learning modular neural network policies for multi-task and multi-robot transfer},
  author = {Devin, Coline and Gupta, Abhishek and Darrell, Trevor and Abbeel, Pieter and Levine, Sergey},
  booktitle = {ICRA},
  year = {2017},
  url = {https://arxiv.org/abs/1609.07088},
}

@misc{duan2017meta,
  title = {Meta-learning for control},
  author = {Duan, Rocky},
  year = {2017},
  url = {https://www2.eecs.berkeley.edu/Pubs/TechRpts/2017/EECS-2017-233.pdf},
}

@inproceedings{finn2017model,
  title = {Model-agnostic meta-learning for fast adaptation of deep networks},
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle = {ICML},
  year = {2017},
  url = {https://arxiv.org/abs/1703.03400},
}

@inproceedings{hausman2017multi,
  title = {Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets},
  author = {Hausman, Karol and Chebotar, Yevgen and Schaal, Stefan and Sukhatme, Gaurav and Lim, Joseph J},
  booktitle = {NeurIPS},
  year = {2017},
  url = {https://arxiv.org/abs/1705.10479},
}

@inproceedings{silver2017predictron,
  title = {The predictron: End-to-end learning and planning},
  author = {Silver, David and van Hasselt, Hado and Hessel, Matteo and Schaul, Tom and Guez, Arthur and Harley, Tim and Dulac{-}Arnold, Gabriel and Reichert, David P. and Rabinowitz, Neil C. and Barreto, André and Degris, Thomas},
  booktitle = {ICML},
  year = {2017},
  url = {https://arxiv.org/abs/1612.08810},
}

@inproceedings{vezhnevets2017feudal,
  title = {FeUdal networks for hierarchical reinforcement learning},
  author = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle = {ICML},
  year = {2017},
  url = {https://arxiv.org/abs/1703.01161},
}

@inproceedings{abel2018policy,
  title = {Policy and Value Transfer in Lifelong Reinforcement Learning},
  author = {Abel, David and Jinnai, Yuu and Guo, Sophie Yue and Konidaris, George and Littman, Michael L.},
  booktitle = {ICML},
  year = {2018},
  url = {http://proceedings.mlr.press/v80/abel18b.html},
}

@inproceedings{dubey2018investigating,
  title = {Investigating Human Priors for Playing Video Games},
  author = {Dubey, Rachit and Agrawal, Pulkit and Pathak, Deepak and Griffiths, Thomas L and Efros, Alexei A},
  booktitle = {ICML},
  year = {2018},
  url = {https://arxiv.org/abs/1802.10217},
}

@inproceedings{frans2018meta,
  title = {Meta-learning shared hierarchies},
  author = {Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
  booktitle = {ICLR},
  year = {2018},
  url = {https://arxiv.org/abs/1710.09767},
}

@inproceedings{ghosh2018divide,
  title = {Divide-and-conquer reinforcement learning},
  author = {Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
  booktitle = {ICLR},
  year = {2018},
  url = {https://arxiv.org/abs/1711.09874},
}

@article{gupta2018meta,
  title = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  author = {Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  booktitle = {NeurIPS},
  year = {2018},
  url = {https://arxiv.org/abs/1802.07245},
}

@inproceedings{hausman2018learning,
  title = {Learning an embedding space for transferable robot skills},
  author = {Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  booktitle = {ICLR},
  year = {2018},
  url = {https://openreview.net/forum?id=rk07ZXZRb},
}

@article{johannink2018residual,
  title = {Residual reinforcement learning for robot control},
  author = {Johannink, Tobias and Bahl, Shikhar and Nair, Ashvin and Luo, Jianlan and Kumar, Avinash and Loskyll, Matthias and Ojea, Juan Aparicio and Solowjow, Eugen and Levine, Sergey},
  journaltitle = {arXiv preprint arXiv:1812.03201},
  year = {2018},
  url = {https://arxiv.org/abs/1812.03201},
}

@inproceedings{ok2018exploration,
  title = {Exploration in Structured Reinforcement Learning},
  author = {Ok, Jungseul and Proutiere, Alexandre and Tranos, Damianos},
  booktitle = {NeurIPS},
  year = {2018},
  url = {https://arxiv.org/abs/1806.00775},
}

@inproceedings{osband2018randomized,
  title = {Randomized Prior Functions for Deep Reinforcement Learning},
  author = {Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle = {NeurIPS},
  year = {2018},
  url = {https://arxiv.org/abs/1806.03335},
}

@inproceedings{saemundsson2018meta,
  title = {Meta Reinforcement Learning with Latent Variable Gaussian Processes},
  author = {Sæmundsson, Steindór and Hofmann, Katja and Deisenroth, Marc Peter},
  booktitle = {UAI},
  year = {2018},
  url = {https://arxiv.org/abs/1803.07551},
}

@inproceedings{sanchez2018graph,
  title = {Graph networks as learnable physics engines for inference and control},
  author = {Sanchez-Gonzalez, Alvaro and Heess, Nicolas and Springenberg, Jost Tobias and Merel, Josh and Riedmiller, Martin and Hadsell, Raia and Battaglia, Peter},
  booktitle = {ICML},
  year = {2018},
  url = {https://arxiv.org/abs/1806.01242},
}

@inproceedings{chang2019automatically,
  title = {Automatically Composing Representation Transformations as a Means for Generalization},
  author = {Chang, Michael B. and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L.},
  booktitle = {ICLR},
  year = {2019},
  url = {https://arxiv.org/abs/1807.04640},
}

@inproceedings{lowrey2019plan,
  title = {Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control},
  author = {Lowrey, Kendall and Rajeswaran, Aravind and Kakade, Sham and Todorov, Emanuel and Mordatch, Igor},
  booktitle = {ICLR},
  year = {2019},
  url = {https://arxiv.org/abs/1811.01848},
}

